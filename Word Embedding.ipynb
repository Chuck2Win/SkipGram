{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sparse Representation\n",
    "# one hot code -> 단어 간의 의미적 유사도를 계산할 수 없다.\n",
    "cat=torch.eye(10)[1].unsqueeze(0)\n",
    "dog=torch.eye(10)[2].unsqueeze(0)\n",
    "print(cat)\n",
    "print(dog)\n",
    "# cosine similarity\n",
    "torch.cosine_similarity(cat,dog) #2차원이 들어가야 계산이 되네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Representation\n",
    "# 기존 one hot code에서는 한 단어 벡터의 크기가 사전의 크기(V) 였다면\n",
    "# Dense Representation은 말 그대로 조밀하게 p(사용자가 설정)<V 크기의 단어 벡터로 표현한다\n",
    "# 그 중에 Word Embedding이 있는 것이지.\n",
    "# Word Embedding에는 LSA, Word2Vec, FastText,Glove 등\n",
    "# nn.embedding은 그런 식으로 학습하진 않지만, 일단 초기값을 뿌려주고 인공 신경망을 학습하는 방식으로 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sat': 2, 'fat': 3, 'cat': 4, 'mat': 5, 'on': 6, '<unknown>': 0, '<pad>': 1}\n"
     ]
    }
   ],
   "source": [
    "#파이토치 nn.Embedding\n",
    "#1.nn.Embedding 사용안하고 해보기\n",
    "train_data='fat cat sat on mat'\n",
    "word_set=list(set(train_data.split()))\n",
    "vocab={word:i+2 for i,word in enumerate(word_set)}\n",
    "vocab['<unknown>']=0\n",
    "vocab['<pad>']=1\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5424, -0.0771,  0.3859],\n",
      "        [ 0.5276, -0.6132,  1.2975],\n",
      "        [-2.4163,  0.6620,  0.4395],\n",
      "        [ 0.1368, -1.1697, -0.1608],\n",
      "        [ 0.6540, -0.1137,  0.3055],\n",
      "        [ 0.2320, -0.5457,  0.8811],\n",
      "        [ 0.4329,  2.0432,  1.5313],\n",
      "        [ 0.6038, -0.3162, -0.6576]])\n"
     ]
    }
   ],
   "source": [
    "#embedding 차원 3\n",
    "embedding_table=torch.randn(8,3)\n",
    "print(embedding_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4045, -0.0377,  0.1053],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [-0.2510,  0.3454, -0.8466]],\n",
       "\n",
       "        [[ 0.7546, -0.2437, -2.0312],\n",
       "         [ 0.2316,  0.6847, -0.1808],\n",
       "         [-0.9449, -0.2146,  0.0965]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=nn.Embedding(10,3,2)\n",
    "#With padding_idx set, the embedding vector at padding_idx is initialized to all zeros.\n",
    "m(torch.LongTensor([[1,2,3],[4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word embedding 구현해보기\n",
    "#CBoW\n",
    "text='''자기 자신의 의지력으로 본능을 이겨야 하고, 꾸준히 규칙적인 운동을 해야하기 때문이다 특히 100KG 이상의 비만 대상인 경우는 더더욱. 다이어트가 괴로운 근본적인 이유가 여기에 있다. 인간을 포함한 모든 동물들은 원래 최대한 덜 움직이고 높은 열량의 먹이를 최대한 많이 먹어 두는것을 본능적으로 선호한다. 그게 야생에서는 생존과 직결되고, 문명화 이후의 인간도 근대 이전 수없이 긴 세월을 그렇게 살아왔다.\n",
    "\n",
    "그런데 혀와 배부름에서 오는 행복을 어느 날 갑자기 포기하는 것도 모자라, 최대한 많이 움직이기까지 해야 하는 다이어트가 최소 몇 개월씩 지속되어야한다는 것이 얼마나 스트레스가 심할까? 게다가 요요 현상이 오지 않게 평생에 걸쳐 관리까지 해야 한다. 단기적으로는 가능하더라도 평생 지속한다는 것은 거의 불가능에 가까운 일이다. 일반인을 갑자기 대회 준비하는 운동 선수처럼 굴리면 안되는 근본적인 이유인데. 단순히 배고프고, 귀찮고, 짜증나는 정도가 아니라 극심한 스트레스와 피로 때문에 되려 없던 병에 걸릴 수도 있다. 선수라면 휴식 스케쥴도 엄연히 일의 일부라 자유롭게 조절하지만 대부분 일반인이라면 최상의 휴식을 통한 컨디션 조절은 커녕 밤샘 안하고 제때 잠이라도 자면 다행인 현실에 놓여있다. 일례로 축구선수들의 훈련 영상을 보면 알겠지만 그들은 빡센 운동량과 식이조절 못지않게 지친 몸을 풀어주고 스트레스를 해소해주는 전문적인 과정도 함께 거친다. 심지어 식욕을 포기한 대신 담배나 술에 의존하는 운동선수들도 상당히 많다. 즉 헝그리 정신 하나만으로 버틴다는 건 문자 그대로 불가능하다. 아무리 힘들어도 몸 이쁘게 만드는 게 가장 보람차고 즐겁다는 보디빌더들도 비시즌기에는 몸이 상당히 붇거나 초췌해진다. 숨 쉬는 것을 참아서 자살하는 것이 불가능한 것처럼 인간의 의지력은 생존본능을 절대 이길 수 없다. [7]\n",
    "\n",
    "그래서 금주보다도 더 괴로운 것이 다이어트라고 한다.[8] 술은 자유롭게 할 수 있는 기호품이지만, 음식은 주기적으로 입에 넣어주기는 해야 하기에 매번 바로 눈앞에서 식욕을 자극한다. 그래서 식사 시간만 되면 고도비만 이하 살 빼는 사람들은 자기 입이 시한폭탄이다. 그 이유는 식사야말로 가장 자연스럽고 근본적인 행위이자, 모두가 해야만 하는 행위이고, 모두가 좋아하는 행위기 때문이다. 술은 직접적으로 건강을 해친다는 이유나 종교적인 이유로 거부하는 문화가 상당히 정착됐으나, 맛있는 식사를 거부하는 행위는 직설적으로 말해 자학적이고 변태적인 성향에 가깝기 때문에 절대 그렇지 않다. 인류는 수십만년간 어떻게 하면 맛있게 먹을 수 있을까?(혹은 먹을 수 있게 만들까?)에 신경썼지 어떻게 하면 내가 풍족한 식사를 끊고 그냥 오래 살까를 고민하지 않았다. 오로지 평범한 인간을 넘고자 하는 종교인들만이 그 고행을 선택했다.\n",
    "\n",
    "하지만 종교인들이 주로 행하는 금식은 건강에 엄청난 위험을 줄 수 있다. 위와 장에 무리가 갈 수 있으므로 금식에는 철저한 준비와 금식 후 보식으로 몸을 천천히 되돌려야한다. 대인관계를 끊으려고 의도하지도 않았는데 주변인들과의 관계가 자연스레 악화되는 것을 신경쓰지 않고 멘탈을 유지할 수 있는 사람은 아무도 없다.\n",
    "\n",
    "\"이번에는 꼭 살 빼야지\" 하고 아주 쉽게 다짐하고는 \"역시 안 되겠다\" 며 아주 쉽게 포기하는 작심삼일일 경우가 매우 많은데 이는 대다수가 건강이나 콤플렉스 등의 이유로 꼭 필요해서가 아니라 그냥 날씬해지고 싶다는 욕망으로 도전했다가 장기간에 걸쳐 노력하는 게 힘들어서 포기해 버리기 때문이다.\n",
    "\n",
    "사회생활도 다이어트의 주적이다. 당신이 학생이건 직장인이건, 점심시간만 되면 밥을 아예 먹지않거나 자신만의 도시락을 꺼내서 먹는 패턴이 처음에는 받아들여지겠지만 그게 주 단위, 월 단위로 보면 주변 사람들의 시선도 곱게 보지않는다. 그나마 학생이면 친구들끼리 양해를 구하는 선에서 마무리가 되거나 혼밥먹으면 그만이지만 직장인이라면.. 그것뿐이라면 모르겠지만 무엇보다도 회식을 피할 수 없는 경우가 많아 더욱 문제가 된다. 회식을 하는 시간대가 저녁, 즉 몸에 지방이 축적되기 쉬운 시간대인 경우가 대부분이며 회식에서 먹는 것이 술에다가 기름진 음식인 경우가 많기 때문에 사회생활 이전까지 열심히 체중 관리를 했다고 하더라도 무용지물이 되는 경우가 많다. 가족들과 식단을 맞추기도 힘들다. 가족들이 어떤 음식을 하건 다이어트를 하는 당신은 당신의 식단을 지켜야하는데, 문제는 집안 분위기에 따라 스무스하게 넘어가는 곳도 있고 정반대인 곳도 있다는것. 후자의 경우 매일 아침과 저녁식사는 사실상 전쟁이다. 즉 이러한 사회생활과의 타협점을 어디에 둘지 결정하는것도 엄청난 정신적 고통이라 할 것이다. 너무 주변사람들 리듬에 맞춰주면 다이어트의 효과가 없고, 반대로 자신만의 길을 걷는다면 주변사람들이 점점 멀어질것이며, 중도를 걷는다해도 어쩌다 한번 먹은 기름진 음식이 당신의 의지를 흐트러트릴 것이다. 치팅 직후에도 비슷한 고통을 겪을 수 밖에 없는데, 오랜만에 맛있는 음식을 먹고나서 원래의 식단으로 돌아가는것은 정말 고통스러운 일이다. 이짓거릴 약 4에서 5일마다 한번씩 겪다보면 정신병이 오는건 아닌가 할 정도로 스트레스를 극심하게 받는다.\n",
    "\n",
    "또 하나, 남녀불문하고 나이가 들어가면서 비만이 느는데, 이는 청년기 정점을 지나고 나면 몸이 노화되면서 기초대사량이 자연스레 줄어들기 때문이다. 청년때 먹어도 살이 찌지 않다가 나이가 들면서 예전과 같은 식사량을 유지하여도 살이 찌게 된다. 나이가 들면서 근육이 빠지면서 기초대사량이 줄어들기 때문이다. 그러기에 나이가 들수록 소식을 해야하고 그에 맞게 먹는 것을 줄이지 않으면 살이 찐다. 그런데 기초대사량 변화는 스스로 느낄수 있는 것이 아니므로 식사량 조절 필요성 또한 모르고, 혹 안다 해도 수십년간 해 온 식습관을 바꾸는 것은 아주 힘들다. 식습관을 바꿀 수 없다면 꾸준한 운동을 통해 근육량을 늘려 기초대사량을 늘려야한다.[9]\n",
    "\n",
    "다이어트는 물론이고 그 결과를 유지하는 것이 얼마나 성공하기 힘든지는 할리우드 스타들만 봐도 알 수 있다. 그 몸이 좋은 스타들도 작품이나 활동만 끝나면 폭풍처럼 몸매가 망가지는 걸 생각해보자. 브리트니 스피어스는 하도 요요 현상과 다이어트를 반복하는 바람에, 이젠 그녀의 몸매 변화에 대한 찌라시의 뉴스는 일상이 되어버린 지 오래.\n",
    "\n",
    "또한 연예인들의 자살사유가 우울증 때문인 경우가 많은데, 이 우울증이 몸매관리에 의한 스트레스인 경우가 많다고 한다. 이 말은 살빼는 것보다 뺀것을 유지하는게 훨씬 더 힘들다는 방증이다.\n",
    "\n",
    "그렇다고는 해도 실제로 필사적으로 다이어트하는 경우보다는 체중계 숫자나 손에 잡히는 군살이나 겉보기 살집이 좀 거슬린다거나 해서 \"살 좀 빼야겠네~\" 하고 막연히 생각하는 경우가 대부분이라 맛있는 것이나 게으름의 유혹에 쉽사리 넘어가는 일이 많을 뿐 본인이 정말 독하게 마음먹으면 조금씩이나마 빠진다.\n",
    "\n",
    "여하튼 중요한 것은 바로 본인의 의지. 의지드립인거 같지만 넘어가자. 단순히 생활패턴을 지속하는 의지 뿐만 아니라 한번 실수하더라도 포기하지 않는 불굴의 멘탈이 필요하다. 정말로. 다이어트를 진지하게 결심했다면 매우 장기전을 뛰어야하는데, 겨우 한 번의 실수로 포기하면 의미없다.\n",
    "\n",
    "그리고 꾸준한 노력. 가끔 6개월에서 18개월 사이에 20kg 이상을 빼는 사람들이 보이며[10] 주위의 부러움을 사기도 하는데 단순히 살 많이 빠져서 부럽다고만 생각하기 전에 그들이 그 시간 동안 얼마나 피나는 노력을 했을지 생각해 보자. 사실 이런 사람들은 다이어트 전에는 고도비만 이상으로 심각한 비만일 경우가 가장 많다. 다만 살이란 건 천천히 빼야지 무턱대고 단기간에 많이 빼버리면 얼굴이 폭삭 늙게 된다. 지방은 얼굴의 피하지방부터 빠지는데 이게 너무 급속히 빠지면 바람 빠진 풍선처럼 쪼글쪼글해진다는 모양. 무한도전 모델 화보 촬영 당시에 정준하가 살을 뺐다가 노안이 되었던 걸 생각해보면 된다. 고도비만인 경우, 자기 관리에 있어서 무엇보다도 다이어트를 하는 것이 급선무일 것이다. 고도비만은 사회적 편견이 심하며, 차별과 불이익이 많다. 처음 고도비만인 사람들이 다이어트를 시도하면 열심히 해도 1~3kg까지만 빠지고 좌절하여 포기하는 경우가 많은데, 다이어트를 진지하게 하고 나서 한번 살이 빠지기 시작하면 쉽게 쭉쭉 빠진다.[11]\n",
    "\n",
    "문제는 비만이 아닌 사람이 다이어트해서 체지방률을 5~10%로 만들어서 몸매를 만드는 경우인데, 비만인 사람이 다이어트해서 체지방을 감량하는 것보다 살이 빠지는 속도가 느리기에 인내심 뿐만 아니라 더 많은 시간을 필요로 한다.\n",
    "\n",
    "게다가 체지방을 감량할 수록 살이 빠지는 속도는 점점 느려지는 경향이 있다. 조급함 때문에 정체기에서 자괴감을 갖고 닥달하거나 포기하는 경우가 있는데 이런 패턴은 지극히 정상이고, 몸짱이 되기 위해 살을 빼는 것은 비만을 탈출하려고 살을 빼는 것보다 더 많은 시간이 걸린다는 사실을 깨닫고 꾸준히 밀고나가야 한다.\n",
    "\n",
    "또 힘든 이유로 재정 상태를 꼽을 수 있는데 성공적인 다이어트를 위해선 저지방, 고단백은 기본이며 신선한 야채, 과일 등을 먹어서 고른 영양소를 섭취할 수 있어야 한다. 하지만 당장 마트에 가도 5끼를 먹을 수 있는 라면 한 봉지와 샐러드를 위한 재료들을 놓고 비교해서 보면 알 수 있을 것이다. 거기다 피티에 단백질 보충제까지 먹어야 한다면 돈은 더더욱 깨질 것이다. 실제로도 저소득층일수록 비만일 가능성이 높다는 자료도 있다.#\n",
    "\n",
    "일과 운동을 병행하는 사람과 운동에만 집중할 수 있는 사람 둘 중 누가 효율이 높은지는 불보듯 뻔한 일이다. 물론 식스팩이 드러난 조각같은 몸이 아니라 적당한 몸매를 유지하고 싶은 정도라면 식단 없이 적게 먹고 많이 움직이기만 해도 다이어트는 가능하다. 돈도 아낄겸 적게 먹고 한 정거장 정도는 걸어가보는 등 작은 일부터 실천해보자.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "ok=Okt()\n",
    "# 일단 해당 text를 문장 단위로 나눠 주자\n",
    "sentences=text.split('.')\n",
    "nouns=[ok.nouns(i) for i in sentences]\n",
    "sentences_nouns=[]\n",
    "for sentence in nouns:\n",
    "    result=\"\"\n",
    "    for noun in sentence:\n",
    "        result=result+\" \"+noun\n",
    "    \n",
    "    sentences_nouns.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit to one hot encoding\n",
    "class vocabulary:\n",
    "    def __init__(self,input_data):\n",
    "        # input data : list form\n",
    "        # [[단어, 단어],[단어,단어],...] 로 구성\n",
    "        self.vocabulary={}\n",
    "        self.vocab_len=0\n",
    "        for sentence in input_data:\n",
    "            if sentence: # 명사가 없는 문장은 제외하자\n",
    "                for noun in sentence:\n",
    "                    if noun not in self.vocabulary.keys():\n",
    "                        self.vocabulary[noun]=self.vocab_len\n",
    "                        self.vocab_len+=1\n",
    "        Result=[]\n",
    "        Result2=[]\n",
    "        for sentence in input_data:\n",
    "            if sentence: # 명사가 없는 문장은 제외하자\n",
    "                result=[]\n",
    "                result2=[]\n",
    "                empty=[[1 if j==i  else 0 for j in range(self.vocab_len)] for i in range(self.vocab_len)]\n",
    "                for noun in sentence:\n",
    "                    result.append(empty[self.vocabulary[noun]])\n",
    "                    result2.append(self.vocabulary[noun])\n",
    "                Result.append(np.array(result))\n",
    "                Result2.append(np.array(result2))\n",
    "        self.one_hot_coded=np.array(Result)\n",
    "        self.digitized=np.array(Result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=vocabulary(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.one_hot_coded[0].shape\n",
    "v.digitized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [0, 1, 2], [0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex=['a','b','c','d','e']\n",
    "# wanna be\n",
    "# a b c\n",
    "# a b c d\n",
    "# a b c d e\n",
    "# b c d e\n",
    "# c d e\n",
    "n=2\n",
    "Result=[]\n",
    "for i,_ in enumerate(ex):\n",
    "    #i=0\n",
    "    #i=1\n",
    "    #i=2\n",
    "    #i=3\n",
    "    #i=4\n",
    "    #...\n",
    "    result=[]\n",
    "    for j in range(i-n,i+n):\n",
    "        if j in range(0,len(ex)):\n",
    "            result.append(j)\n",
    "    Result.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data 만들기\n",
    "# 자기 자신 의지력 본능 규칙 운동 때문 이상 비만 대상 경우 더 더욱\n",
    "# window size : 2\n",
    "# 자기 자신 \n",
    "# 자기 의지력\n",
    "# 자신 자기 \n",
    "# 자신 의지력 \n",
    "# 자신 본능\n",
    "# 의지력 자기\n",
    "# 의지력 자신\n",
    "# 의지력 본능\n",
    "# 의지력 규칙\n",
    "# 본능 자신\n",
    "# 본능 의지력\n",
    "# 본능 규칙\n",
    "# 본능 운동 ...\n",
    "def make_data(input_data,window_size):\n",
    "    #input data : digitized\n",
    "    # input data shape : [batch size, seq len]\n",
    "    data=[]\n",
    "    for seq in input_data:\n",
    "        for _,i in enumerate(seq):\n",
    "            result_index=[j for j in range(_-window_size,_+window_size+1) if j in range(len(seq))]\n",
    "            result_index.remove(_)\n",
    "            result=[seq[k] for k in result_index]\n",
    "            for l in result:\n",
    "                data.append([i,l])\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2814, 2)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#window size 2\n",
    "train_data=make_data(v.digitized,2)\n",
    "np.array(train_data).shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2814, 454)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data를 one hot coded로 바꿔야한다\n",
    "\n",
    "# 그 전에 input 값과 out put 값 변환\n",
    "x_train = np.array(train_data)[:,0]\n",
    "y_train = np.array(train_data)[:,1]\n",
    "\n",
    "# x_train을 one hot code로 변환한다\n",
    "onehot=np.eye(v.vocab_len)\n",
    "x_train_one_hot=np.array([onehot[i] for i in x_train])\n",
    "x_train_one_hot.shape #2814,454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skip_gram(nn.Module):\n",
    "    def __init__(self,input_dim,embedding_dim):\n",
    "        self.input_dim=input_dim\n",
    "        self.embedding_dim=embedding_dim\n",
    "        super().__init__()\n",
    "        self.i2h=nn.Linear(self.input_dim,self.embedding_dim,bias=False)\n",
    "        self.h2o=nn.Linear(self.embedding_dim,self.input_dim,bias=False)\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        out=self.i2h.forward(input_data)\n",
    "        out=self.h2o.forward(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import visdom\n",
    "vis=visdom.Visdom()\n",
    "vis.close(env='main')\n",
    "pt=vis.line(Y=[0.],X=[0],opts=dict(title='Train',showlegend=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "device='cuda:0'\n",
    "model=skip_gram(454,100).to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters(),0.01)\n",
    "cost_list=[]\n",
    "for i in range(300):\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    optimizer.zero_grad()\n",
    "    x=torch.FloatTensor(x_train_one_hot).to(device)\n",
    "    y=torch.LongTensor(y_train).to(device)\n",
    "    predict=model.forward(x)\n",
    "    cost=F.cross_entropy(predict,y)\n",
    "    cost_list.append(cost.item())\n",
    "    pt=vis.line(Y=[cost.item()],X=[i],win=pt,update='append')\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1be11308748>]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 454])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#비만과 가장 가까운 단어를 찾아보자\n",
    "# W(look up table)을 가져오자\n",
    "list(model.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "W=list(model.parameters())[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#다이어트\n",
    "v.vocabulary['다이어트']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fat=torch.zeros(454)\n",
    "x_fat[13]=1\n",
    "# x_fat의 embedding vector 확인\n",
    "W.shape#100,454\n",
    "v_fat=torch.mv(W,x_fat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.eye(454)\n",
    "V=torch.mm(W,X)\n",
    "sim=[]\n",
    "for _,i in enumerate(V.T):\n",
    "    sim.append((torch.cosine_similarity(i.unsqueeze(0),V.T[13].unsqueeze(0)).item(),_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 : 숫자 -> 단어 \n",
    "vocabulary_d2w=dict()\n",
    "for key,value in v.vocabulary.items():\n",
    "    vocabulary_d2w[value]=key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['다이어트', '무용지물', '아무', '필사', '대상', '이하', '좌절', '가족', '문제', '시간', '중도', '금주', '탈출', '피', '모자라', '소득', '로', '효과', '전', '여기', '중', '체지방률', '더욱', '사이', '의지', '관계', '결과', '식', '체지방', '줄', '흐트러', '평생', '최소', '주적', '꼽', '리듬', '젠', '게다가', '시작', '수록', '숫자', '다해', '삼일일', '인내심', '자기', '이자', '당신', '일', '영양소', '위해', '굴리', '살', '장기전', '경우', '대다수', '해도', '반복', '실제', '시도', '오지', '작심', '급선무', '이전', '몇', '좀', '곱', '사람', '집중', '주변', '회식', '감량', '습관', '콤플렉스', '무엇', '만', '고도', '점점', '필요', '생각', '문자', '십년', '유지', '현상', '선수', '체중', '길', '준비', '청년', '그것', '정신', '악화', '밀고', '한번', '위험', '보이', '사실', '비만', '술', '축적', '알', '개월', '반대', '이상', '음식', '해', '기호품', '방증', '다만', '찌게', '사회생활', '지속', '우울증', '멘탈', '스케쥴', '저녁식사', '매우', '결심', '스피어스', '구', '신경', '찌', '처음', '매일', '타협', '할리우드', '겉보기', '피하지방', '대부분', '또한', '것', '스트레스', '대고', '나이', '편견', '몸매', '정말', '여하튼', '자살', '가장', '관리', '도비', '속도', '제', '풍선', '불문', '입', '때문', '혹', '가능성', '심지어', '이건', '아침', '금식', '정도', '시간대', '식단', '건', '전쟁', '유혹', '가도', '둘', '말', '정상', '동물', '층', '집안', '라면', '덜', '학생', '봉지', '몸짱', '상태', '숨', '바로', '실천', '일이', '주위', '쭉쭉', '섭취', '실수', '도', '그대로', '변화', '걸', '나가야', '불가능', '트릴', '갑자기', '식사', '식욕', '소식', '고통', '그', '행', '대신', '기적', '이', '살집', '시선', '동안', '점', '고행', '노력', '후자', '컨디션', '가끔', '성공', '최상', '직후', '내', '친구', '폭삭', '쉽사리', '폭탄', '온', '때', '통해', '아주', '끼', '수', '경향', '약', '무리', '담배', '단위', '바람', '생활', '요요', '행위', '이유', '혼밥', '지방', '운동량', '근본', '직설', '살이', '저녁', '닥', '이면', '주로', '무턱', '즉', '의지력', '먹이', '최대한', '건강', '만이', '선호', '결정', '며', '움', '훈련', '스스로', '식사량', '그녀', '단백', '기본', '샐러드', '본능', '의존', '날', '양해', '운동', '변태', '매번', '활동', '분위기', '일부', '포기', '거의', '종교', '야채', '대인관계', '자료', '손', '원래', '장', '치팅', '현실', '비교', '모두', '선택', '대회', '게으름', '하나', '영상', '주변인', '기', '조각', '모양', '드립', '또', '성향', '보', '제때', '등', '주기', '정준하', '병', '꼭', '더', '통한', '의도', '인류', '문화', '거기', '휴식', '패턴', '정신병', '불보듯', '사유', '부러', '돈', '연예인', '뉴스', '선', '의미', '축구선수', '폭풍', '겨우', '자극', '일반인', '역시', '그냥', '규칙', '누가', '움직', '피티', '이번', '직장인', '거부', '조절', '브리트니', '얼마나', '만년', '전문', '모델', '직접', '재정', '대한', '밤샘', '군살', '열량', '작품', '단기간', '종교인', '일과', '다행', '자신', '이짓거릴', '빡센', '점심시간', '식스', '촬영', '본인', '스타', '인간', '병행', '정반대', '과일', '불굴', '피나', '아예', '커녕', '다짐', '보지', '월', '마무리', '사회', '몸', '잠', '사기', '피로', '모든', '단백질', '운동선수', '이유나', '재료', '번의', '당시', '세월', '끼리', '감', '뿐', '당장', '노안', '정거장', '필요성', '수도', '헝그리', '를', '량', '후', '도시락', '어디', '게', '포함', '안', '사람과', '밥', '보충', '근육', '얼굴', '절대', '팩', '일상', '무한도전', '일례', '겸', '차별', '효율', '과정', '찌라시', '정체', '생존', '마트', '이후', '스', '근대', '붇거', '고민', '정착', '기초', '사량', '행복', '자학', '정점', '곳도', '빼', '주', '혀', '화보', '조금', '문명', '예전', '눈앞', '욕망', '해소', '식이', '보람', '차고', '자괴', '비', '위', '장기간', '도전', '노화', '남녀', '시즌', '그게', '보디빌더', '직결', '불이익', '야생']\n"
     ]
    }
   ],
   "source": [
    "similary_vocab_for_fat_digit=sorted(sim,key=lambda i : i[0],reverse=True)\n",
    "similary_vocab_for_fat=[vocabulary_d2w[i[1]] for i in similary_vocab_for_fat_digit]\n",
    "print(similary_vocab_for_fat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('약', 0.2538357377052307),\n",
       " ('규칙', 0.252014696598053),\n",
       " ('자극', 0.22417528927326202),\n",
       " ('분위기', 0.21458548307418823),\n",
       " ('탈출', 0.21426922082901),\n",
       " ('기호품', 0.21334683895111084),\n",
       " ('수', 0.2052830457687378),\n",
       " ('선호', 0.20375320315361023),\n",
       " ('노화', 0.20015573501586914),\n",
       " ('갑자기', 0.1989457607269287)]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gensim과 비교해보자\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# 꿀 팁 : 쥬피터에서 함수의 자동완성을 원한다면 tab을 누르고 함수의 설명을 원한다면 tab+shift\n",
    "# sentences로는 [[ 단어,단어,단어 .. ], 문장2 , ... ] 요로코롬\n",
    "model_g=word2vec.Word2Vec(sentences=nouns,size=100,\n",
    "    window=2,\n",
    "    min_count=0,\n",
    "    max_vocab_size=None,\n",
    "    sg=1,\n",
    "    negative=0)\n",
    "#model_g.wv.most_similar('비만')\n",
    "\n",
    "model_g.wv.most_similar('다이어트')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
